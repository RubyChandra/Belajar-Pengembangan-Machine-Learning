# -*- coding: utf-8 -*-
"""LSTM_TIME_SERIES

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13n-_r3CANS33vSGCTNj8iQsvzSdH70Rd

# Library
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, Lambda

"""# Dataset
from: https://www.kaggle.com/datasets/shenba/time-series-datasets
"""

data_frame = pd.read_csv('daily-minimum-temperatures-in-me.csv', parse_dates=['Date'])
data_frame = data_frame._convert(numeric=True)
data_frame_2 = data_frame.dropna()
data_frame_2.describe()

print(data_frame_2.shape)
print(data_frame_2['Date'].min())
print(data_frame_2['Date'].max())

data_frame_2.info()

plt.figure(figsize=(30,8))
plt.plot(data_frame_2['Date'], data_frame_2['Daily minimum temperatures'])
plt.title('Daily minimum temperatures',
          fontsize=20)
plt.xticks(weight='bold', fontsize=12, rotation=45)
plt.yticks(weight='bold', fontsize=12)
plt.grid(color = 'y', linewidth = 0.5)

data_frame_2.set_index('Date', inplace=True)
data_frame_2.sort_index(inplace=True)

"""# SPLITTING USING TIMESERIESSPLIT"""

tscv = TimeSeriesSplit(n_splits=4)

X = data_frame_2.drop(labels=['Daily minimum temperatures'],axis=1)
y = data_frame_2['Daily minimum temperatures']

for train_index, val_index in tscv.split(X):
  X_train, X_val = X.iloc[train_index, :], X.iloc[val_index,:]
  y_train, y_val = y.iloc[train_index], y.iloc[val_index]

X_train.index

X_val.index

"""2918 (0.8) || 729 (0.2)

# Transform to Windowed Format
"""

def windowed_dataset(series, window_size=100, batch_size=64, shuffle_buffer=1000):
	dataset = tf.data.Dataset.from_tensor_slices(series)
	dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
	dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
	dataset = dataset.shuffle(shuffle_buffer)
	dataset = dataset.map(lambda window: (window[:-1], window[-1]))
	dataset = dataset.batch(batch_size).prefetch(1)
	return dataset

train_set = windowed_dataset(y_train)
val_set = windowed_dataset(y_val)

"""# Build Model"""

model = Sequential()
model.add(Lambda(lambda x: tf.expand_dims(x, axis=-1),
                    input_shape=[None]))
model.add(LSTM(60))
model.add(Dropout(0.2))
model.add(Dense(8, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(1))
model.summary()

"""# Calculating Max_MAE"""

#menghitung 10% dari skala data
maximum = max(y)
minimum = min(y)
maximum_mae = (maximum-minimum)*0.1
print(maximum_mae)

"""# Build Custom Callback"""

class EarlyStopping(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    
    if(logs.get('mae') <= maximum_mae*0.9):
      print("\nMAEthreshold reached. Training stopped.")
      self.model.stop_training = True

early_stopping = EarlyStopping()

"""# Compiling and Fitting Model"""

model.compile(loss=tf.keras.losses.Huber(),
              # optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              optimizer=tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9),
              metrics=["mae"])
history = model.fit(train_set,
                    validation_data=val_set,
                    epochs=30,
                    verbose=2,
                    callbacks=[[early_stopping]])

"""# PLOT MAE dan LOSS"""

f = plt.figure(figsize=(12,3))
plt.subplot(1, 2, 1)
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('model mae')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')

plt.show()